{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "from pyspark.sql.functions import col, explode\n",
        "\n",
        "# Now you can use these imported elements\n",
        "spark = SparkSession.builder.appName(\"MyPySparkApp\").getOrCreate()\n",
        "# schema = StructType([\n",
        "#     StructField(\"name\", StringType(), True),\n",
        "#     StructField(\"age\", IntegerType(), True)\n",
        "# ])\n",
        "\n",
        "# #### merge 2 DFs\n",
        "\n",
        "\n",
        "\n",
        "simpleData = [(1,\"Sagar\", \"CSE\", \"UP\",80,), \\\n",
        "(2, \"Shivam\", \"IT\", \"MP\", 86,),\n",
        "(3, \"Muni\", \"Mech\", \"AP\", 70,)\\\n",
        "]\n",
        "columns= [\"ID\", \"Student_Name\", \"Department_Name\", \"City\", \"Marks\"]\n",
        "df1 = spark.createDataFrame(data = simpleData, schema = columns)\n",
        "df1.show()\n",
        "\n",
        "\n",
        "simpleData_2 = [(5, \"Raj\", \"CSE\", \"HP\"), \\\n",
        "(7, \"Kunal\", \"Mech\", \"Rajasthan\") \\\n",
        "]\n",
        "columns_2= [\"ID\", \"Student_Name\", \"Department_Name\",\"City\"]\n",
        "df2 = spark.createDataFrame(data = simpleData_2, schema = columns_2)\n",
        "\n",
        "df2.show()\n",
        "\n",
        "udf=df1.unionByName(df2,allowMissingColumns=True)\n",
        "udf.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSHVQhsgDLqR",
        "outputId": "6f7e57bb-b6f5-4dc2-ad6f-3a7dabfb5991"
      },
      "id": "rSHVQhsgDLqR",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------+---------------+----+-----+\n",
            "| ID|Student_Name|Department_Name|City|Marks|\n",
            "+---+------------+---------------+----+-----+\n",
            "|  1|       Sagar|            CSE|  UP|   80|\n",
            "|  2|      Shivam|             IT|  MP|   86|\n",
            "|  3|        Muni|           Mech|  AP|   70|\n",
            "+---+------------+---------------+----+-----+\n",
            "\n",
            "+---+------------+---------------+---------+\n",
            "| ID|Student_Name|Department_Name|     City|\n",
            "+---+------------+---------------+---------+\n",
            "|  5|         Raj|            CSE|       HP|\n",
            "|  7|       Kunal|           Mech|Rajasthan|\n",
            "+---+------------+---------------+---------+\n",
            "\n",
            "+---+------------+---------------+---------+-----+\n",
            "| ID|Student_Name|Department_Name|     City|Marks|\n",
            "+---+------------+---------------+---------+-----+\n",
            "|  1|       Sagar|            CSE|       UP|   80|\n",
            "|  2|      Shivam|             IT|       MP|   86|\n",
            "|  3|        Muni|           Mech|       AP|   70|\n",
            "|  5|         Raj|            CSE|       HP| NULL|\n",
            "|  7|       Kunal|           Mech|Rajasthan| NULL|\n",
            "+---+------------+---------------+---------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #### use of explode function\n",
        "\n",
        "\n",
        "simpleData = [ (1, [\"Sagar\", \"Prajapati\"]), (2,[\"Shivam\", \"Gupta\"]), (3,[\"Kunal\", \"Verma\"]), (4, [\"Kim\"])]\n",
        "columns=[\"ID\", \"Name\"]\n",
        "\n",
        "sdf=spark.createDataFrame(simpleData,schema=columns)\n",
        "\n",
        "sdf.show()\n",
        "\n",
        "ndf=sdf.withColumn(\"new_name\",explode(col(\"Name\")))\n",
        "ndf.select(\"id\",\"new_name\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRFSCqJwEhUt",
        "outputId": "fcaa7462-a3d4-4efa-87de-5d0628c12391"
      },
      "id": "mRFSCqJwEhUt",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------------+\n",
            "| ID|              Name|\n",
            "+---+------------------+\n",
            "|  1|[Sagar, Prajapati]|\n",
            "|  2|   [Shivam, Gupta]|\n",
            "|  3|    [Kunal, Verma]|\n",
            "|  4|             [Kim]|\n",
            "+---+------------------+\n",
            "\n",
            "+---+---------+\n",
            "| id| new_name|\n",
            "+---+---------+\n",
            "|  1|    Sagar|\n",
            "|  1|Prajapati|\n",
            "|  2|   Shivam|\n",
            "|  2|    Gupta|\n",
            "|  3|    Kunal|\n",
            "|  3|    Verma|\n",
            "|  4|      Kim|\n",
            "+---+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find valid mobile numbers\n",
        "\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "\n",
        "dataset1=[(2,'shivam','u9886755443244B'),(3,'abhi','u886755kp244B'),(4,'shwetha','u7886755gt244B'),(5,'jack','7886755244')]\n",
        "columns=[\"id\",\"name\",'mobile']\n",
        "\n",
        "mobileDF=spark.createDataFrame(dataset1,schema=columns)\n",
        "mobileDF.show()\n",
        "mobileDF.withColumn(\"nmobile\",regexp_replace(col(\"mobile\"),\"[^0-9]\",\"\")).show()\n",
        "\n",
        "mobileDF.filter(col(\"mobile\").rlike(\"^[0-9]*$\")).show()\n"
      ],
      "metadata": {
        "id": "73OKSFeocNdw",
        "outputId": "b0ed7507-70e0-4805-b0ca-61b4d789c253",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "73OKSFeocNdw",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+---------------+\n",
            "| id|   name|         mobile|\n",
            "+---+-------+---------------+\n",
            "|  2| shivam|u9886755443244B|\n",
            "|  3|   abhi|  u886755kp244B|\n",
            "|  4|shwetha| u7886755gt244B|\n",
            "|  5|   jack|     7886755244|\n",
            "+---+-------+---------------+\n",
            "\n",
            "+---+-------+---------------+-------------+\n",
            "| id|   name|         mobile|      nmobile|\n",
            "+---+-------+---------------+-------------+\n",
            "|  2| shivam|u9886755443244B|9886755443244|\n",
            "|  3|   abhi|  u886755kp244B|    886755244|\n",
            "|  4|shwetha| u7886755gt244B|   7886755244|\n",
            "|  5|   jack|     7886755244|   7886755244|\n",
            "+---+-------+---------------+-------------+\n",
            "\n",
            "+---+----+----------+\n",
            "| id|name|    mobile|\n",
            "+---+----+----------+\n",
            "|  5|jack|7886755244|\n",
            "+---+----+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}